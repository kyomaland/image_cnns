{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cassava build Model.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOiGUac4/GmKkYG/sXDNpPz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyomaland/image_cnns/blob/master/Cassava_build_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yqszpoj_4-V"
      },
      "source": [
        "#For accessing Google Cloud Store\n",
        "!pip install gcsfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90FjmYDwv4Vf"
      },
      "source": [
        "import math, os, re, warnings, random\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "#from kaggle_datasets import KaggleDatasets\n",
        "from tensorflow.keras import optimizers, applications, Sequential, losses, metrics, layers\n",
        "#import tensorflow.keras.layers as L\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from sklearn.model_selection import KFold\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from functools import partial\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "seed = 0\n",
        "seed_everything(seed)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "try: # detect TPUs\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "except ValueError: # detect GPUs\n",
        "    #strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
        "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n",
        "REPLICAS = strategy.num_replicas_in_sync\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSIPVWW8-XnD"
      },
      "source": [
        "#AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "IMAGE_SIZE = [512, 512]\n",
        "#IMAGE_SIZE = [224, 224]\n",
        "BATCH_SIZE = 8 * REPLICAS \n",
        "LEARNING_RATE = 1e-4 * REPLICAS #1e-5\n",
        "EPOCHS = 100 #30\n",
        "HEIGHT = 512\n",
        "WIDTH = 512\n",
        "CHANNELS = 3\n",
        "N_CLASSES = 5\n",
        "ES_PATIENCE = 10 #5\n",
        "N_FOLDS = 5\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    n = [int(re.compile(r'-([0-9]*)\\.').search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)\n",
        "\n",
        "\n",
        "#database_base_path = '/content/input/raw'\n",
        "##database_base_path = '/tmp/kaggle-data'\n",
        "###training_path = '/tmp/kaggle-data'\n",
        "###train = pd.read_csv(f'{database_base_path}/train.csv')\n",
        "###print(f'Train samples: {len(train)}')\n",
        "\n",
        "#GCS_PATH = training_path\n",
        "#GCS_PATH = get_gcs_path()\n",
        "#GCS_PATH = 'gs://kds-7edb6b200570e03505c2c8b51546e17bfef2e493ee048343ac8fd722'\n",
        "GCS_PATH = 'gs://kds-5aa0bc7b16935d65ef6334184486ee9ab86d9e404dfad4bd4c32200c'\n",
        "print(GCS_PATH)\n",
        "print(\"#####\")\n",
        "\n",
        "print(GCS_PATH + '/train_tfrecords/ld_train*.tfrec')\n",
        "#GCS_PATH = KaggleDatasets().get_gcs_path('cassava-leaf-disease-classification') # Original dataset\n",
        "# GCS_PATH = KaggleDatasets().get_gcs_path(f'cassava-leaf-disease-tfrecords-{HEIGHT}x{WIDTH}') # Only resized\n",
        "##GCS_PATH = KaggleDatasets().get_gcs_path(f'cassava-leaf-disease-tfrecords-center-{HEIGHT}x{WIDTH}') # Center croped and resized\n",
        "\n",
        "#TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train_tfrecords/*.tfrec') # Original TFRecords\n",
        "##TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/*.tfrec')\n",
        "\n",
        "TRAINING_FILENAMES, VALIDATION_FILENAMES = train_test_split(\n",
        "    tf.io.gfile.glob(GCS_PATH + '/train_tfrecords/ld_train*.tfrec'), test_size=0.2, random_state=42) #test_size=0.35\n",
        "\n",
        "###TEST_FILENAMES = tf.io.gfile.glob(database_base_path + '/ld_test*.tfrec')\n",
        "TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test_tfrecords/ld_test*.tfrec')\n",
        "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "\n",
        "\n",
        "print(f'GCS: train images: {NUM_TRAINING_IMAGES}')\n",
        "##display(train.head())\n",
        "\n",
        "CLASSES = ['Bacterial Blight', \n",
        "           'Brown Streak', \n",
        "           'Green Mottle', \n",
        "           'Mosaic Disease', \n",
        "           'Healthy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAwZBqUhxima"
      },
      "source": [
        "# Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrDlEAJ9-Xxg"
      },
      "source": [
        "# numpy and matplotlib defaults\n",
        "np.set_printoptions(threshold=15, linewidth=80)\n",
        "\n",
        "def batch_to_numpy_images_and_labels(data):\n",
        "    images, labels = data\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "    if numpy_labels.dtype == object: # binary string in this case, these are image ID strings\n",
        "        numpy_labels = [None for _ in enumerate(numpy_images)]\n",
        "    # If no labels, only image IDs, return None for labels (this is the case for test data)\n",
        "    return numpy_images, numpy_labels\n",
        "\n",
        "def title_from_label_and_target(label, correct_label):\n",
        "    if correct_label is None:\n",
        "        return CLASSES[label], True\n",
        "    correct = (label == correct_label)\n",
        "    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n",
        "                                CLASSES[correct_label] if not correct else ''), correct\n",
        "\n",
        "def display_one_flower(image, title, subplot, red=False, titlesize=16):\n",
        "    plt.subplot(*subplot)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "    if len(title) > 0:\n",
        "        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n",
        "    return (subplot[0], subplot[1], subplot[2]+1)\n",
        "    \n",
        "def display_batch_of_images(databatch, predictions=None):\n",
        "    \"\"\"This will work with:\n",
        "    display_batch_of_images(images)\n",
        "    display_batch_of_images(images, predictions)\n",
        "    display_batch_of_images((images, labels))\n",
        "    display_batch_of_images((images, labels), predictions)\n",
        "    \"\"\"\n",
        "    # data\n",
        "    images, labels = batch_to_numpy_images_and_labels(databatch)\n",
        "    if labels is None:\n",
        "        labels = [None for _ in enumerate(images)]\n",
        "        \n",
        "    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n",
        "    rows = int(math.sqrt(len(images)))\n",
        "    cols = len(images)//rows\n",
        "        \n",
        "    # size and spacing\n",
        "    FIGSIZE = 13.0\n",
        "    SPACING = 0.1\n",
        "    subplot=(rows,cols,1)\n",
        "    if rows < cols:\n",
        "        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n",
        "    else:\n",
        "        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n",
        "    \n",
        "    # display\n",
        "    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n",
        "        title = '' if label is None else CLASSES[label]\n",
        "        correct = True\n",
        "        if predictions is not None:\n",
        "            title, correct = title_from_label_and_target(predictions[i], label)\n",
        "        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n",
        "        subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n",
        "    \n",
        "    #layout\n",
        "    plt.tight_layout()\n",
        "    if label is None and predictions is None:\n",
        "        plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    else:\n",
        "        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n",
        "    plt.show()\n",
        "\n",
        "def display_confusion_matrix(cmat, score, precision, recall):\n",
        "    plt.figure(figsize=(50,50))\n",
        "    ax = plt.gca()\n",
        "    ax.matshow(cmat, cmap='Reds')\n",
        "    ax.set_xticks(range(len(CLASSES)))\n",
        "    ax.set_xticklabels(CLASSES, fontdict={'fontsize': 7})\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n",
        "    ax.set_yticks(range(len(CLASSES)))\n",
        "    ax.set_yticklabels(CLASSES, fontdict={'fontsize': 7})\n",
        "    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "    titlestring = \"\"\n",
        "    if score is not None:\n",
        "        titlestring += 'f1 = {:.3f} '.format(score)\n",
        "    if precision is not None:\n",
        "        titlestring += '\\nprecision = {:.3f} '.format(precision)\n",
        "    if recall is not None:\n",
        "        titlestring += '\\nrecall = {:.3f} '.format(recall)\n",
        "    if len(titlestring) > 0:\n",
        "        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n",
        "    plt.show()\n",
        "    \n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "    if subplot%10==1: # set up the subplots on the first call\n",
        "        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
        "        plt.tight_layout()\n",
        "    ax = plt.subplot(subplot)\n",
        "    ax.set_facecolor('#F8F8F8')\n",
        "    ax.plot(training)\n",
        "    ax.plot(validation)\n",
        "    ax.set_title('model '+ title)\n",
        "    ax.set_ylabel(title)\n",
        "    #ax.set_ylim(0.28,1.05)\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.legend(['train', 'valid.'])\n",
        "\n",
        "# Model evaluation, for K-FOLD\n",
        "def plot_metrics(history):\n",
        "    metric_list = [m for m in list(history.keys()) if m is not 'lr']\n",
        "    size = len(metric_list)//2\n",
        "    fig, axes = plt.subplots(size, 1, sharex='col', figsize=(20, size * 4))\n",
        "    if size > 1:\n",
        "        axes = axes.flatten()\n",
        "    else:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for index in range(len(metric_list)//2):\n",
        "        metric_name = metric_list[index]\n",
        "        val_metric_name = metric_list[index+size]\n",
        "        axes[index].plot(history[metric_name], label='Train %s' % metric_name)\n",
        "        axes[index].plot(history[val_metric_name], label='Validation %s' % metric_name)\n",
        "        axes[index].legend(loc='best', fontsize=16)\n",
        "        axes[index].set_title(metric_name)\n",
        "        if 'loss' in metric_name:\n",
        "            axes[index].axvline(np.argmin(history[metric_name]), linestyle='dashed')\n",
        "            axes[index].axvline(np.argmin(history[val_metric_name]), linestyle='dashed', color='orange')\n",
        "        else:\n",
        "            axes[index].axvline(np.argmax(history[metric_name]), linestyle='dashed')\n",
        "            axes[index].axvline(np.argmax(history[val_metric_name]), linestyle='dashed', color='orange')\n",
        "\n",
        "    plt.xlabel('Epochs', fontsize=16)\n",
        "    sns.despine()\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EpYCmM7yAjI"
      },
      "source": [
        "# Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z323tp9U-X0Y"
      },
      "source": [
        "def data_augment(image, label):\n",
        "    p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_shear = 0\n",
        "    \n",
        "    # Shear\n",
        "    if p_shear > .2:\n",
        "        if p_shear > .6:\n",
        "            image = transform_shear(image, HEIGHT, shear=20.)\n",
        "        else:\n",
        "            image = transform_shear(image, HEIGHT, shear=-20.)\n",
        "            \n",
        "    # Rotation\n",
        "    if p_rotation > .2:\n",
        "        if p_rotation > .6:\n",
        "            image = transform_rotation(image, HEIGHT, rotation=45.)\n",
        "        else:\n",
        "            image = transform_rotation(image, HEIGHT, rotation=-45.)\n",
        "            \n",
        "    # Flips\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    if p_spatial > .75:\n",
        "        image = tf.image.transpose(image)\n",
        "        \n",
        "    # Rotates\n",
        "    if p_rotate > .75:\n",
        "        image = tf.image.rot90(image, k=3) # rotate 270º\n",
        "    elif p_rotate > .5:\n",
        "        image = tf.image.rot90(image, k=2) # rotate 180º\n",
        "    elif p_rotate > .25:\n",
        "        image = tf.image.rot90(image, k=1) # rotate 90º\n",
        "        \n",
        "    # Pixel-level transforms\n",
        "    if p_pixel_1 >= .4:\n",
        "        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n",
        "    if p_pixel_2 >= .4:\n",
        "        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n",
        "    if p_pixel_3 >= .4:\n",
        "        image = tf.image.random_brightness(image, max_delta=.1)\n",
        "        \n",
        "    # Crops\n",
        "    if p_crop > .6:\n",
        "        if p_crop > .9:\n",
        "            image = tf.image.central_crop(image, central_fraction=.5)\n",
        "        elif p_crop > .8:\n",
        "            image = tf.image.central_crop(image, central_fraction=.6)\n",
        "        elif p_crop > .7:\n",
        "            image = tf.image.central_crop(image, central_fraction=.7)\n",
        "        else:\n",
        "            image = tf.image.central_crop(image, central_fraction=.8)\n",
        "    elif p_crop > .3:\n",
        "        crop_size = tf.random.uniform([], int(HEIGHT*.6), HEIGHT, dtype=tf.int32)\n",
        "        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n",
        "            \n",
        "    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\n",
        "\n",
        "    if p_cutout > .5:\n",
        "        image = data_augment_cutout(image)\n",
        "        \n",
        "    return image, label\n",
        "\n",
        "def data_augment_spatial(image):\n",
        "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    if p_spatial > .75:\n",
        "        image = tf.image.transpose(image)\n",
        "\n",
        "    return image\n",
        "\n",
        "def data_augment_rotate(image):\n",
        "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    \n",
        "    if p_rotate > .66:\n",
        "        image = tf.image.rot90(image, k=3) # rotate 270º\n",
        "    elif p_rotate > .33:\n",
        "        image = tf.image.rot90(image, k=2) # rotate 180º\n",
        "    else:\n",
        "        image = tf.image.rot90(image, k=1) # rotate 90º\n",
        "\n",
        "    return image\n",
        "\n",
        "def data_augment_crop(image):\n",
        "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    crop_size = tf.random.uniform([], int(HEIGHT*.7), HEIGHT, dtype=tf.int32)\n",
        "    \n",
        "    if p_crop > .5:\n",
        "        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n",
        "    else:\n",
        "        if p_crop > .4:\n",
        "            image = tf.image.central_crop(image, central_fraction=.7)\n",
        "        elif p_crop > .2:\n",
        "            image = tf.image.central_crop(image, central_fraction=.8)\n",
        "        else:\n",
        "            image = tf.image.central_crop(image, central_fraction=.9)\n",
        "    \n",
        "    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "# CutOut\n",
        "def data_augment_cutout(image, min_mask_size=(int(HEIGHT * .1), int(HEIGHT * .1)), \n",
        "                        max_mask_size=(int(HEIGHT * .125), int(HEIGHT * .125))):\n",
        "    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    \n",
        "    if p_cutout > .85: # 10~15 cut outs\n",
        "        n_cutout = tf.random.uniform([], 10, 15, dtype=tf.int32)\n",
        "        image = random_cutout(image, HEIGHT, WIDTH, \n",
        "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n",
        "    elif p_cutout > .6: # 5~10 cut outs\n",
        "        n_cutout = tf.random.uniform([], 5, 10, dtype=tf.int32)\n",
        "        image = random_cutout(image, HEIGHT, WIDTH, \n",
        "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n",
        "    elif p_cutout > .25: # 2~5 cut outs\n",
        "        n_cutout = tf.random.uniform([], 2, 5, dtype=tf.int32)\n",
        "        image = random_cutout(image, HEIGHT, WIDTH, \n",
        "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n",
        "    else: # 1 cut out\n",
        "        image = random_cutout(image, HEIGHT, WIDTH, \n",
        "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=1)\n",
        "\n",
        "    return image\n",
        "\n",
        "def random_cutout(image, height, width, channels=3, min_mask_size=(10, 10), max_mask_size=(80, 80), k=1):\n",
        "    assert height > min_mask_size[0]\n",
        "    assert width > min_mask_size[1]\n",
        "    assert height > max_mask_size[0]\n",
        "    assert width > max_mask_size[1]\n",
        "\n",
        "    for i in range(k):\n",
        "      mask_height = tf.random.uniform(shape=[], minval=min_mask_size[0], maxval=max_mask_size[0], dtype=tf.int32)\n",
        "      mask_width = tf.random.uniform(shape=[], minval=min_mask_size[1], maxval=max_mask_size[1], dtype=tf.int32)\n",
        "\n",
        "      pad_h = height - mask_height\n",
        "      pad_top = tf.random.uniform(shape=[], minval=0, maxval=pad_h, dtype=tf.int32)\n",
        "      pad_bottom = pad_h - pad_top\n",
        "\n",
        "      pad_w = width - mask_width\n",
        "      pad_left = tf.random.uniform(shape=[], minval=0, maxval=pad_w, dtype=tf.int32)\n",
        "      pad_right = pad_w - pad_left\n",
        "\n",
        "      cutout_area = tf.zeros(shape=[mask_height, mask_width, channels], dtype=tf.uint8)\n",
        "\n",
        "      cutout_mask = tf.pad([cutout_area], [[0,0],[pad_top, pad_bottom], [pad_left, pad_right], [0,0]], constant_values=1)\n",
        "      cutout_mask = tf.squeeze(cutout_mask, axis=0)\n",
        "      image = tf.multiply(tf.cast(image, tf.float32), tf.cast(cutout_mask, tf.float32))\n",
        "\n",
        "    return image    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsMNh4XK1Hoa"
      },
      "source": [
        "# Auxilliary Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQR55zOy-X3w"
      },
      "source": [
        "# data augmentation @cdeotte kernel: https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96\n",
        "def transform_rotation(image, height, rotation):\n",
        "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
        "    # output - image randomly rotated\n",
        "    DIM = height\n",
        "    XDIM = DIM%2 #fix for size 331\n",
        "    \n",
        "    rotation = rotation * tf.random.uniform([1],dtype='float32')\n",
        "    # CONVERT DEGREES TO RADIANS\n",
        "    rotation = math.pi * rotation / 180.\n",
        "    \n",
        "    # ROTATION MATRIX\n",
        "    c1 = tf.math.cos(rotation)\n",
        "    s1 = tf.math.sin(rotation)\n",
        "    one = tf.constant([1],dtype='float32')\n",
        "    zero = tf.constant([0],dtype='float32')\n",
        "    rotation_matrix = tf.reshape(tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3])\n",
        "\n",
        "    # LIST DESTINATION PIXEL INDICES\n",
        "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
        "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
        "    z = tf.ones([DIM*DIM],dtype='int32')\n",
        "    idx = tf.stack( [x,y,z] )\n",
        "    \n",
        "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
        "    idx2 = K.dot(rotation_matrix,tf.cast(idx,dtype='float32'))\n",
        "    idx2 = K.cast(idx2,dtype='int32')\n",
        "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
        "    \n",
        "    # FIND ORIGIN PIXEL VALUES \n",
        "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
        "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
        "        \n",
        "    return tf.reshape(d,[DIM,DIM,3])\n",
        "\n",
        "def transform_shear(image, height, shear):\n",
        "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
        "    # output - image randomly sheared\n",
        "    DIM = height\n",
        "    XDIM = DIM%2 #fix for size 331\n",
        "    \n",
        "    shear = shear * tf.random.uniform([1],dtype='float32')\n",
        "    shear = math.pi * shear / 180.\n",
        "        \n",
        "    # SHEAR MATRIX\n",
        "    one = tf.constant([1],dtype='float32')\n",
        "    zero = tf.constant([0],dtype='float32')\n",
        "    c2 = tf.math.cos(shear)\n",
        "    s2 = tf.math.sin(shear)\n",
        "    shear_matrix = tf.reshape(tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3])    \n",
        "\n",
        "    # LIST DESTINATION PIXEL INDICES\n",
        "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
        "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
        "    z = tf.ones([DIM*DIM],dtype='int32')\n",
        "    idx = tf.stack( [x,y,z] )\n",
        "    \n",
        "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
        "    idx2 = K.dot(shear_matrix,tf.cast(idx,dtype='float32'))\n",
        "    idx2 = K.cast(idx2,dtype='int32')\n",
        "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
        "    \n",
        "    # FIND ORIGIN PIXEL VALUES \n",
        "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
        "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
        "        \n",
        "    return tf.reshape(d,[DIM,DIM,3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2UdIpnN6CJj"
      },
      "source": [
        "# Data Handling Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJzYGvYc1QtC"
      },
      "source": [
        "def decode_image1(image_data):\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)  # image format uint8 [0,255]\n",
        "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n",
        "    return image\n",
        "\n",
        "# Datasets utility functions\n",
        "def decode_image(image_data):\n",
        "    \"\"\"\n",
        "        Decode a JPEG-encoded image to a uint8 tensor.\n",
        "    \"\"\"\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    return image\n",
        "\n",
        "def scale_image(image, label):\n",
        "    \"\"\"\n",
        "        Cast tensor to float and normalizes (range between 0 and 1).\n",
        "    \"\"\"\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255.0\n",
        "    return image, label\n",
        "\n",
        "def prepare_image(image, label):\n",
        "    \"\"\"\n",
        "        Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    image = tf.image.resize(image, [HEIGHT, WIDTH])\n",
        "    image = tf.reshape(image, [HEIGHT, WIDTH, 3])\n",
        "    return image, label\n",
        "\n",
        "def read_tfrecord(example, labeled):\n",
        "    tfrecord_format = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
        "    } if labeled else {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "    \n",
        "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
        "    image = decode_image(example['image'])\n",
        "    if labeled:\n",
        "        label = tf.cast(example['target'], tf.int32)\n",
        "        return image, label\n",
        "    idnum = example['image_name']\n",
        "    return image, idnum\n",
        "\"\"\"   \n",
        "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
        "    image = decode_image(example['image'])\n",
        "    if labeled:\n",
        "        label_or_name = tf.cast(example['target'], tf.int32)\n",
        "        # One-Hot Encoding needed to use \"categorical_crossentropy\" loss\n",
        "        label_or_name = tf.one_hot(tf.cast(label_or_name, tf.int32), N_CLASSES)\n",
        "    else:\n",
        "        label_or_name = example['image_name']\n",
        "    return image, label_or_name\n",
        "\"\"\"\n",
        "##\n",
        "\n",
        "\"\"\"\n",
        "def read_labeled_tfrecord(example):\n",
        "    LABELED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
        "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
        "    image = decode_image(example['image'])\n",
        "    label = tf.cast(example['class'], tf.int32)\n",
        "    return image, label # returns a dataset of (image, label) pairs\n",
        "\n",
        "def read_unlabeled_tfrecord(example):\n",
        "    UNLABELED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
        "        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n",
        "        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
        "    image = decode_image(example['image'])\n",
        "    idnum = example['id']\n",
        "    return image, idnum # returns a dataset of image(s)\n",
        "\n",
        "def load_dataset(filenames, labeled=True, ordered=False):\n",
        "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
        "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n",
        "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
        "    return dataset\n",
        "\"\"\"\n",
        "\n",
        "def load_dataset(filenames, labeled=True, ordered=False):\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def get_dataset(FILENAMES, labeled=True, ordered=False, repeated=False, \n",
        "                cached=False, augment=False):\n",
        "    \"\"\"\n",
        "        Return a Tensorflow dataset ready for training or inference.\n",
        "    \"\"\"\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False\n",
        "        dataset = tf.data.Dataset.list_files(FILENAMES)\n",
        "        dataset = dataset.interleave(tf.data.TFRecordDataset, num_parallel_calls=AUTO)\n",
        "    else:\n",
        "        dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads=AUTO)\n",
        "        \n",
        "    dataset = dataset.with_options(ignore_order)\n",
        "    \n",
        "    dataset = dataset.map(lambda x: read_tfrecord(x, labeled=labeled), num_parallel_calls=AUTO)\n",
        "    \n",
        "    if augment:\n",
        "        dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
        "        \n",
        "    dataset = dataset.map(scale_image, num_parallel_calls=AUTO)\n",
        "    dataset = dataset.map(prepare_image, num_parallel_calls=AUTO)\n",
        "    \n",
        "    if not ordered:\n",
        "        dataset = dataset.shuffle(2048)\n",
        "    if repeated:\n",
        "        dataset = dataset.repeat()\n",
        "        \n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    \n",
        "    if cached:\n",
        "        dataset = dataset.cache()\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        "\n",
        "def data_augment1(image, label):\n",
        "    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n",
        "    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n",
        "    # of the TPU while the TPU itself is computing gradients.\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_saturation(image, 0, 2)\n",
        "    return image, label   \n",
        "\n",
        "def get_training_dataset():\n",
        "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n",
        "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
        "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "    return dataset\n",
        "\n",
        "def get_validation_dataset(ordered=False):\n",
        "    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "    return dataset\n",
        "\n",
        "def get_test_dataset(ordered=False):\n",
        "    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "    return dataset\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)\n",
        "\n",
        "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "NUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\n",
        "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
        "STEPS_PER_EPOCH = -(-NUM_TRAINING_IMAGES // BATCH_SIZE)\n",
        "VALIDATION_STEPS = -(-NUM_VALIDATION_IMAGES // BATCH_SIZE) # The \"-(-//)\" trick rounds up instead of down :-)\n",
        "TEST_STEPS = (NUM_TEST_IMAGES // BATCH_SIZE)             # The \"-(-//)\" trick rounds up instead of down :-)\n",
        "print('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))\n",
        "print(STEPS_PER_EPOCH, VALIDATION_STEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lipl4uwc7z5m"
      },
      "source": [
        "#Data Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa5wX4zl1QxY"
      },
      "source": [
        "# data dump\n",
        "print(\"Training data shapes:\")\n",
        "for image, label in get_training_dataset().take(3):\n",
        "    print(image.numpy().shape, label.numpy().shape)\n",
        "print(\"Training data label examples:\", label.numpy())\n",
        "print(\"Validation data shapes:\")\n",
        "for image, label in get_validation_dataset().take(3):\n",
        "    print(image.numpy().shape, label.numpy().shape)\n",
        "print(\"Validation data label examples:\", label.numpy())\n",
        "print(\"Test data shapes:\")\n",
        "for image, idnum in get_test_dataset().take(3):\n",
        "    print(image.numpy().shape, idnum.numpy().shape)\n",
        "print(\"Test data IDs:\", idnum.numpy().astype('U')) # U=unicode string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv3uUkvW1QzC"
      },
      "source": [
        "# Peek at training data\n",
        "training_dataset = get_training_dataset()\n",
        "training_dataset = training_dataset.unbatch().batch(20)\n",
        "train_batch = iter(training_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9pMQYnH1Q1p"
      },
      "source": [
        "train_dataset = get_dataset(TRAINING_FILENAMES, ordered=True, augment=True)\n",
        "train_iter = iter(train_dataset.unbatch().batch(20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3IxKTSH_MT2"
      },
      "source": [
        "display_batch_of_images(next(train_iter))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDQEnzKa_MfD"
      },
      "source": [
        "# peer at test data\n",
        "test_dataset = get_test_dataset()\n",
        "test_dataset = test_dataset.unbatch().batch(1)\n",
        "test_batch = iter(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEv0Z_zo_WgZ"
      },
      "source": [
        "# run this cell again for next set of images\n",
        "display_batch_of_images(next(test_batch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BbJx5nf_p3Z"
      },
      "source": [
        "#Label Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7KqYTcQ_dlk"
      },
      "source": [
        "train = pd.read_csv(f'{GCS_PATH}/train.csv')\n",
        "print(f'Train samples: {len(train)}')\n",
        "label_count = train.groupby('label', as_index=False).count()\n",
        "label_count.rename(columns={'image_id': 'Count', 'label': 'Label'}, inplace=True)\n",
        "label_count['Label'] = label_count['Label'].apply(lambda x: CLASSES[x])\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(18, 10))\n",
        "ax = sns.barplot(x=label_count['Count'], y=label_count['Label'], palette='viridis')\n",
        "ax.tick_params(labelsize=16)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXr5kxGaAQz4"
      },
      "source": [
        "#Balancing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAFF6HIx_dzY"
      },
      "source": [
        "total_images = label_count['Count'].sum()\n",
        "print(total_images)\n",
        "#print(count_data_items(TRAINING_FILENAMES) + count_data_items(VALIDATION_FILENAMES))\n",
        "#TRAIN_IMG_COUNT = COUNT_NORMAL + COUNT_PNEUMONIA\n",
        "label_count['weights'] = (1 / label_count['Count']) * (total_images) / 5.0\n",
        "#label_count['weights2'] = (total_images) /((label_count['Count']) * 5.0)\n",
        "#weight_for_1 = (1 / COUNT_PNEUMONIA) * (TRAIN_IMG_COUNT) / 2.0\n",
        "print(label_count)\n",
        "class_weight = dict(zip(label_count.index, label_count.weights))\n",
        "print(f'The weights are {class_weight}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnL7Bt3EAioH"
      },
      "source": [
        "#Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeTE29DGtDpC"
      },
      "source": [
        "#es = tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy', mode='max',\n",
        "                       #patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\n",
        "\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='sparse_categorical_accuracy', mode='auto',\n",
        "                       patience=ES_PATIENCE, restore_best_weights=True, verbose=2) #'val_loss'\n",
        "\n",
        "\n",
        "# Save the model with the minimum validation loss\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "        \"Cassava_new_best_model.h5\",\n",
        "        save_best_only=True,\n",
        "        monitor='sparse_categorical_accuracy',\n",
        "        mode='auto')\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='sparse_categorical_accuracy', #'val_loss'\n",
        "        factor=0.3,\n",
        "        patience=3,#2\n",
        "        #min_lr=1e-12,\n",
        "        mode='auto',\n",
        "        verbose=2,\n",
        "    )\n",
        "\n",
        "initial_learning_rate = 0.015\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MSLPODXAwVo"
      },
      "source": [
        "#The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El4JNCxFAyMr"
      },
      "source": [
        "def conv_block(filters, inputs):\n",
        "  x = layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
        "  x = layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  outputs = layers.MaxPool2D()(x)\n",
        "\n",
        "  return outputs\n",
        "\n",
        "def dense_block(units, dropout_rate, inputs):\n",
        "  x = layers.Dense(units, activation=\"relu\")(inputs)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  outputs = layers.Dropout(dropout_rate)(x)\n",
        "  return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTXv7jkZAyz8"
      },
      "source": [
        "def build_model():\n",
        "    inputs = keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "    x = preprocessing.Rescaling(1.0 / 255)(inputs)\n",
        "    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "\n",
        "    x = conv_block(32, x)\n",
        "    x = conv_block(64, x)\n",
        "\n",
        "    x = conv_block(128, x)\n",
        "    x = layers.Dropout(0.2)(x)#0.2\n",
        "\n",
        "    x = conv_block(256, x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = dense_block(512, 0.2, x) #0.7\n",
        "    x = dense_block(128, 0.2, x) #0.5\n",
        "    x = dense_block(64, 0.1, x)#0.2\n",
        "\n",
        "    outputs = layers.Dense(5, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35g1-hhzXkKZ"
      },
      "source": [
        "with strategy.scope():\n",
        "    model = build_model()\n",
        "\n",
        "    METRICS = [\n",
        "        ['sparse_categorical_accuracy'],\n",
        "        tf.keras.metrics.Precision(name=\"precision\"),\n",
        "        tf.keras.metrics.Recall(name=\"recall\"),\n",
        "    ]\n",
        "    model.compile(\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate = LEARNING_RATE), #learning_rate=lr_schedule \n",
        "        loss = 'sparse_categorical_crossentropy',\n",
        "        metrics = ['sparse_categorical_accuracy'],\n",
        "        steps_per_execution = 251, #125\n",
        "    )\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG0uKo2JXnnC"
      },
      "source": [
        "history = model.fit(get_dataset(TRAINING_FILENAMES, ordered=False, augment=True).repeat(), \n",
        "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=get_dataset(VALIDATION_FILENAMES, ordered=False, augment=False).repeat(), \n",
        "                    validation_steps=VALIDATION_STEPS,\n",
        "                    #class_weight=class_weight,\n",
        "                    callbacks=[es, checkpoint_cb, reduce_lr] \n",
        "                    )  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NwEIehlwPye"
      },
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, met in enumerate([ \"sparse_categorical_accuracy\", \"loss\"]):\n",
        "    ax[i].plot(history.history[met])\n",
        "    ax[i].plot(history.history[\"val_\" + met])\n",
        "    ax[i].set_title(\"Model {}\".format(met))\n",
        "    ax[i].set_xlabel(\"epochs\")\n",
        "    ax[i].set_ylabel(met)\n",
        "    ax[i].legend([\"train\", \"val\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvzjv9PnDUzD"
      },
      "source": [
        "#cmdataset = get_validation_dataset(ordered=True) # since we are splitting the dataset and iterating separately on images and labels, order matters.\n",
        "cmdataset = get_dataset(VALIDATION_FILENAMES, ordered=True,augment=False) # since we are splitting the dataset and iterating separately on images and labels, order matters.\n",
        "images_ds = cmdataset.map(lambda image, label: image)\n",
        "labels_ds = cmdataset.map(lambda image, label: label).unbatch()\n",
        "cm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy() # get everything as one batch NUM_VALIDATION_IMAGES 8000\n",
        "cm_probabilities = model.predict(images_ds, steps=VALIDATION_STEPS)\n",
        "cm_predictions = np.argmax(cm_probabilities, axis=-1)\n",
        "print(\"Correct   labels: \", cm_correct_labels.shape, cm_correct_labels)\n",
        "print(\"Predicted labels: \", cm_predictions.shape, cm_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh3cBeLqDX9p"
      },
      "source": [
        "cmat = confusion_matrix(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)))\n",
        "score = f1_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n",
        "precision = precision_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n",
        "recall = recall_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n",
        "cmat = (cmat.T / cmat.sum(axis=1)).T # normalized\n",
        "display_confusion_matrix(cmat, score, precision, recall)\n",
        "print('f1 score: {:.3f}, precision: {:.3f}, recall: {:.3f}'.format(score, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdwFRC5ag6YJ"
      },
      "source": [
        "ax1 = plt.subplot()\n",
        "sns.heatmap(cmat, annot=True,ax=ax1)\n",
        "#ax1.set_xticklabels(['']+CLASSES)\n",
        "#ax1.set_yticklabels(['']+CLASSES)\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEqFfdbThCFE"
      },
      "source": [
        "#dataset = get_validation_dataset()\n",
        "dataset = get_dataset(VALIDATION_FILENAMES)\n",
        "dataset = dataset.unbatch().batch(20)\n",
        "batch = iter(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQtIFvPAhDCd"
      },
      "source": [
        "# run this cell again for next set of images\n",
        "images, labels = next(batch)\n",
        "probabilities = model.predict(tf.cast(images, tf.float32))\n",
        "predictions = np.argmax(probabilities, axis=-1)\n",
        "display_batch_of_images((images, labels), predictions)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}