{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Cassava Leaf TPU.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMF8s3g2YNNWn+3PT5SkAOa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyomaland/image_cnns/blob/master/Cassava_Leaf_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahfTXCMC9fFu"
      },
      "source": [
        "# Needed software"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2RrDjE2z9TV"
      },
      "source": [
        " ! mkdir ~/.kaggle\r\n",
        "! cp  kaggle.json ~/.kaggle/\r\n",
        "! chmod 600 ~/.kaggle/kaggle.json\r\n",
        "!kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AXhlVaa0W5I"
      },
      "source": [
        "! kaggle datasets download -d ipythonx/efficientnet-keras-noisystudent-weights-b0b7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK4qTlrc0k3v"
      },
      "source": [
        "!ls\r\n",
        "!unzip efficientnet-keras-noisystudent-weights-b0b7.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpvG-OTn0v3o"
      },
      "source": [
        "!ls -lr  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AXXfxJz9Ayw"
      },
      "source": [
        "#For accessing Google Cloud Store\r\n",
        "!pip install gcsfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6XH2iN0zWUY"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvEDXVZX-GnA"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JI3LsnjF8oN"
      },
      "source": [
        "#import math, re, os\r\n",
        "import math, os, re, warnings, random\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "#from kaggle_datasets import KaggleDatasets\r\n",
        "#from tensorflow.keras import optimizers, applications, Sequential, losses, metrics\r\n",
        "import tensorflow.keras.layers as L\r\n",
        "import tensorflow.keras.backend as K\r\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "print(\"Tensorflow version \" + tf.__version__)\r\n",
        "AUTO = tf.data.experimental.AUTOTUNE\r\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from functools import partial\r\n",
        "from keras.callbacks import Callback\r\n",
        "\r\n",
        "\r\n",
        "def seed_everything(seed=42):\r\n",
        "    random.seed(seed)\r\n",
        "    np.random.seed(seed)\r\n",
        "    tf.random.set_seed(seed)\r\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\r\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\r\n",
        "\r\n",
        "seed = 0\r\n",
        "seed_everything(seed)\r\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fgyFk5wJqJG"
      },
      "source": [
        "# NEW on TPU in TensorFlow 24: shorter cross-compatible TPU/GPU/multi-GPU/cluster-GPU detection code\r\n",
        "\r\n",
        "try: # detect TPUs\r\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\r\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\r\n",
        "except ValueError: # detect GPUs\r\n",
        "    #strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\r\n",
        "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\r\n",
        "    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\r\n",
        "REPLICAS = strategy.num_replicas_in_sync\r\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYQlCiSd-Bea"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC396Q9hJrxK"
      },
      "source": [
        "IMAGE_SIZE = [512, 512]\r\n",
        "#IMAGE_SIZE = [224, 224]\r\n",
        "BATCH_SIZE = 8 * REPLICAS \r\n",
        "LEARNING_RATE = 1e-5 * REPLICAS #1e-5\r\n",
        "EPOCHS = 50 #30\r\n",
        "HEIGHT = 512\r\n",
        "WIDTH = 512\r\n",
        "CHANNELS = 3\r\n",
        "N_CLASSES = 5\r\n",
        "ES_PATIENCE = 10 #5\r\n",
        "N_FOLDS = 5\r\n",
        "\r\n",
        "def count_data_items(filenames):\r\n",
        "    n = [int(re.compile(r'-([0-9]*)\\.').search(filename).group(1)) for filename in filenames]\r\n",
        "    return np.sum(n)\r\n",
        "\r\n",
        "\r\n",
        "#database_base_path = '/content/input/raw'\r\n",
        "##database_base_path = '/tmp/kaggle-data'\r\n",
        "###training_path = '/tmp/kaggle-data'\r\n",
        "###train = pd.read_csv(f'{database_base_path}/train.csv')\r\n",
        "###print(f'Train samples: {len(train)}')\r\n",
        "\r\n",
        "#GCS_PATH = training_path\r\n",
        "#GCS_PATH = get_gcs_path()\r\n",
        "#GCS_PATH = 'gs://kds-7edb6b200570e03505c2c8b51546e17bfef2e493ee048343ac8fd722'\r\n",
        "GCS_PATH = 'gs://kds-5a56e5f04dd7babbea524973e9eb3c1eee821f66118844a14996ecda'\r\n",
        "print(GCS_PATH)\r\n",
        "print(\"#####\")\r\n",
        "\r\n",
        "print(GCS_PATH + '/train_tfrecords/ld_train*.tfrec')\r\n",
        "#GCS_PATH = KaggleDatasets().get_gcs_path('cassava-leaf-disease-classification') # Original dataset\r\n",
        "# GCS_PATH = KaggleDatasets().get_gcs_path(f'cassava-leaf-disease-tfrecords-{HEIGHT}x{WIDTH}') # Only resized\r\n",
        "##GCS_PATH = KaggleDatasets().get_gcs_path(f'cassava-leaf-disease-tfrecords-center-{HEIGHT}x{WIDTH}') # Center croped and resized\r\n",
        "\r\n",
        "#TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train_tfrecords/*.tfrec') # Original TFRecords\r\n",
        "##TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/*.tfrec')\r\n",
        "\r\n",
        "TRAINING_FILENAMES, VALIDATION_FILENAMES = train_test_split(\r\n",
        "    tf.io.gfile.glob(GCS_PATH + '/train_tfrecords/ld_train*.tfrec'), test_size=0.2, random_state=42) #test_size=0.35\r\n",
        "\r\n",
        "###TEST_FILENAMES = tf.io.gfile.glob(database_base_path + '/ld_test*.tfrec')\r\n",
        "TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test_tfrecords/ld_test*.tfrec')\r\n",
        "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\r\n",
        "\r\n",
        "\r\n",
        "print(f'GCS: train images: {NUM_TRAINING_IMAGES}')\r\n",
        "##display(train.head())\r\n",
        "\r\n",
        "CLASSES = ['Bacterial Blight', \r\n",
        "           'Brown Streak', \r\n",
        "           'Green Mottle', \r\n",
        "           'Mosaic Disease', \r\n",
        "           'Healthy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWkEKhj9WGnO"
      },
      "source": [
        "# Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6nbQX17V34J"
      },
      "source": [
        "# numpy and matplotlib defaults\r\n",
        "np.set_printoptions(threshold=15, linewidth=80)\r\n",
        "\r\n",
        "def batch_to_numpy_images_and_labels(data):\r\n",
        "    images, labels = data\r\n",
        "    numpy_images = images.numpy()\r\n",
        "    numpy_labels = labels.numpy()\r\n",
        "    if numpy_labels.dtype == object: # binary string in this case, these are image ID strings\r\n",
        "        numpy_labels = [None for _ in enumerate(numpy_images)]\r\n",
        "    # If no labels, only image IDs, return None for labels (this is the case for test data)\r\n",
        "    return numpy_images, numpy_labels\r\n",
        "\r\n",
        "def title_from_label_and_target(label, correct_label):\r\n",
        "    if correct_label is None:\r\n",
        "        return CLASSES[label], True\r\n",
        "    correct = (label == correct_label)\r\n",
        "    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\r\n",
        "                                CLASSES[correct_label] if not correct else ''), correct\r\n",
        "\r\n",
        "def display_one_flower(image, title, subplot, red=False, titlesize=16):\r\n",
        "    plt.subplot(*subplot)\r\n",
        "    plt.axis('off')\r\n",
        "    plt.imshow(image)\r\n",
        "    if len(title) > 0:\r\n",
        "        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\r\n",
        "    return (subplot[0], subplot[1], subplot[2]+1)\r\n",
        "    \r\n",
        "def display_batch_of_images(databatch, predictions=None):\r\n",
        "    \"\"\"This will work with:\r\n",
        "    display_batch_of_images(images)\r\n",
        "    display_batch_of_images(images, predictions)\r\n",
        "    display_batch_of_images((images, labels))\r\n",
        "    display_batch_of_images((images, labels), predictions)\r\n",
        "    \"\"\"\r\n",
        "    # data\r\n",
        "    images, labels = batch_to_numpy_images_and_labels(databatch)\r\n",
        "    if labels is None:\r\n",
        "        labels = [None for _ in enumerate(images)]\r\n",
        "        \r\n",
        "    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\r\n",
        "    rows = int(math.sqrt(len(images)))\r\n",
        "    cols = len(images)//rows\r\n",
        "        \r\n",
        "    # size and spacing\r\n",
        "    FIGSIZE = 13.0\r\n",
        "    SPACING = 0.1\r\n",
        "    subplot=(rows,cols,1)\r\n",
        "    if rows < cols:\r\n",
        "        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\r\n",
        "    else:\r\n",
        "        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\r\n",
        "    \r\n",
        "    # display\r\n",
        "    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\r\n",
        "        title = '' if label is None else CLASSES[label]\r\n",
        "        correct = True\r\n",
        "        if predictions is not None:\r\n",
        "            title, correct = title_from_label_and_target(predictions[i], label)\r\n",
        "        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\r\n",
        "        subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\r\n",
        "    \r\n",
        "    #layout\r\n",
        "    plt.tight_layout()\r\n",
        "    if label is None and predictions is None:\r\n",
        "        plt.subplots_adjust(wspace=0, hspace=0)\r\n",
        "    else:\r\n",
        "        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "def display_confusion_matrix(cmat, score, precision, recall):\r\n",
        "    plt.figure(figsize=(50,50))\r\n",
        "    ax = plt.gca()\r\n",
        "    ax.matshow(cmat, cmap='Reds')\r\n",
        "    ax.set_xticks(range(len(CLASSES)))\r\n",
        "    ax.set_xticklabels(CLASSES, fontdict={'fontsize': 7})\r\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\r\n",
        "    ax.set_yticks(range(len(CLASSES)))\r\n",
        "    ax.set_yticklabels(CLASSES, fontdict={'fontsize': 7})\r\n",
        "    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\r\n",
        "    titlestring = \"\"\r\n",
        "    if score is not None:\r\n",
        "        titlestring += 'f1 = {:.3f} '.format(score)\r\n",
        "    if precision is not None:\r\n",
        "        titlestring += '\\nprecision = {:.3f} '.format(precision)\r\n",
        "    if recall is not None:\r\n",
        "        titlestring += '\\nrecall = {:.3f} '.format(recall)\r\n",
        "    if len(titlestring) > 0:\r\n",
        "        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\r\n",
        "    plt.show()\r\n",
        "    \r\n",
        "def display_training_curves(training, validation, title, subplot):\r\n",
        "    if subplot%10==1: # set up the subplots on the first call\r\n",
        "        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\r\n",
        "        plt.tight_layout()\r\n",
        "    ax = plt.subplot(subplot)\r\n",
        "    ax.set_facecolor('#F8F8F8')\r\n",
        "    ax.plot(training)\r\n",
        "    ax.plot(validation)\r\n",
        "    ax.set_title('model '+ title)\r\n",
        "    ax.set_ylabel(title)\r\n",
        "    #ax.set_ylim(0.28,1.05)\r\n",
        "    ax.set_xlabel('epoch')\r\n",
        "    ax.legend(['train', 'valid.'])\r\n",
        "\r\n",
        "# Model evaluation, for K-FOLD\r\n",
        "def plot_metrics(history):\r\n",
        "    metric_list = [m for m in list(history.keys()) if m is not 'lr']\r\n",
        "    size = len(metric_list)//2\r\n",
        "    fig, axes = plt.subplots(size, 1, sharex='col', figsize=(20, size * 4))\r\n",
        "    if size > 1:\r\n",
        "        axes = axes.flatten()\r\n",
        "    else:\r\n",
        "        axes = [axes]\r\n",
        "    \r\n",
        "    for index in range(len(metric_list)//2):\r\n",
        "        metric_name = metric_list[index]\r\n",
        "        val_metric_name = metric_list[index+size]\r\n",
        "        axes[index].plot(history[metric_name], label='Train %s' % metric_name)\r\n",
        "        axes[index].plot(history[val_metric_name], label='Validation %s' % metric_name)\r\n",
        "        axes[index].legend(loc='best', fontsize=16)\r\n",
        "        axes[index].set_title(metric_name)\r\n",
        "        if 'loss' in metric_name:\r\n",
        "            axes[index].axvline(np.argmin(history[metric_name]), linestyle='dashed')\r\n",
        "            axes[index].axvline(np.argmin(history[val_metric_name]), linestyle='dashed', color='orange')\r\n",
        "        else:\r\n",
        "            axes[index].axvline(np.argmax(history[metric_name]), linestyle='dashed')\r\n",
        "            axes[index].axvline(np.argmax(history[val_metric_name]), linestyle='dashed', color='orange')\r\n",
        "\r\n",
        "    plt.xlabel('Epochs', fontsize=16)\r\n",
        "    sns.despine()\r\n",
        "    plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3aFtM5zKgYa"
      },
      "source": [
        "# Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Krc2JCC_IsUU"
      },
      "source": [
        "def data_augment(image, label):\r\n",
        "    p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\r\n",
        "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\r\n",
        "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\r\n",
        "    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\r\n",
        "    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\r\n",
        "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\r\n",
        "    p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\r\n",
        "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\r\n",
        "    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\r\n",
        "    p_shear = 0\r\n",
        "    \r\n",
        "    # Shear\r\n",
        "    if p_shear > .2:\r\n",
        "        if p_shear > .6:\r\n",
        "            image = transform_shear(image, HEIGHT, shear=20.)\r\n",
        "        else:\r\n",
        "            image = transform_shear(image, HEIGHT, shear=-20.)\r\n",
        "            \r\n",
        "    # Rotation\r\n",
        "    if p_rotation > .2:\r\n",
        "        if p_rotation > .6:\r\n",
        "            image = transform_rotation(image, HEIGHT, rotation=45.)\r\n",
        "        else:\r\n",
        "            image = transform_rotation(image, HEIGHT, rotation=-45.)\r\n",
        "            \r\n",
        "    # Flips\r\n",
        "    image = tf.image.random_flip_left_right(image)\r\n",
        "    image = tf.image.random_flip_up_down(image)\r\n",
        "    if p_spatial > .75:\r\n",
        "        image = tf.image.transpose(image)\r\n",
        "        \r\n",
        "    # Rotates\r\n",
        "    if p_rotate > .75:\r\n",
        "        image = tf.image.rot90(image, k=3) # rotate 270º\r\n",
        "    elif p_rotate > .5:\r\n",
        "        image = tf.image.rot90(image, k=2) # rotate 180º\r\n",
        "    elif p_rotate > .25:\r\n",
        "        image = tf.image.rot90(image, k=1) # rotate 90º\r\n",
        "        \r\n",
        "    # Pixel-level transforms\r\n",
        "    if p_pixel_1 >= .4:\r\n",
        "        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\r\n",
        "    if p_pixel_2 >= .4:\r\n",
        "        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\r\n",
        "    if p_pixel_3 >= .4:\r\n",
        "        image = tf.image.random_brightness(image, max_delta=.1)\r\n",
        "        \r\n",
        "    # Crops\r\n",
        "    if p_crop > .6:\r\n",
        "        if p_crop > .9:\r\n",
        "            image = tf.image.central_crop(image, central_fraction=.5)\r\n",
        "        elif p_crop > .8:\r\n",
        "            image = tf.image.central_crop(image, central_fraction=.6)\r\n",
        "        elif p_crop > .7:\r\n",
        "            image = tf.image.central_crop(image, central_fraction=.7)\r\n",
        "        else:\r\n",
        "            image = tf.image.central_crop(image, central_fraction=.8)\r\n",
        "    elif p_crop > .3:\r\n",
        "        crop_size = tf.random.uniform([], int(HEIGHT*.6), HEIGHT, dtype=tf.int32)\r\n",
        "        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\r\n",
        "            \r\n",
        "    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\r\n",
        "\r\n",
        "    if p_cutout > .5:\r\n",
        "        image = data_augment_cutout(image)\r\n",
        "        \r\n",
        "    return image, label\r\n",
        "\r\n",
        "def data_augment_spatial(image):\r\n",
        "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\r\n",
        "\r\n",
        "    image = tf.image.random_flip_left_right(image)\r\n",
        "    image = tf.image.random_flip_up_down(image)\r\n",
        "    if p_spatial > .75:\r\n",
        "        image = tf.image.transpose(image)\r\n",
        "\r\n",
        "    return image\r\n",
        "\r\n",
        "def data_augment_rotate(image):\r\n",
        "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\r\n",
        "    \r\n",
        "    if p_rotate > .66:\r\n",
        "        image = tf.image.rot90(image, k=3) # rotate 270º\r\n",
        "    elif p_rotate > .33:\r\n",
        "        image = tf.image.rot90(image, k=2) # rotate 180º\r\n",
        "    else:\r\n",
        "        image = tf.image.rot90(image, k=1) # rotate 90º\r\n",
        "\r\n",
        "    return image\r\n",
        "\r\n",
        "def data_augment_crop(image):\r\n",
        "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\r\n",
        "    crop_size = tf.random.uniform([], int(HEIGHT*.7), HEIGHT, dtype=tf.int32)\r\n",
        "    \r\n",
        "    if p_crop > .5:\r\n",
        "        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\r\n",
        "    else:\r\n",
        "        if p_crop > .4:\r\n",
        "            image = tf.image.central_crop(image, central_fraction=.7)\r\n",
        "        elif p_crop > .2:\r\n",
        "            image = tf.image.central_crop(image, central_fraction=.8)\r\n",
        "        else:\r\n",
        "            image = tf.image.central_crop(image, central_fraction=.9)\r\n",
        "    \r\n",
        "    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\r\n",
        "\r\n",
        "    return image\r\n",
        "\r\n",
        "\r\n",
        "# CutOut\r\n",
        "def data_augment_cutout(image, min_mask_size=(int(HEIGHT * .1), int(HEIGHT * .1)), \r\n",
        "                        max_mask_size=(int(HEIGHT * .125), int(HEIGHT * .125))):\r\n",
        "    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\r\n",
        "    \r\n",
        "    if p_cutout > .85: # 10~15 cut outs\r\n",
        "        n_cutout = tf.random.uniform([], 10, 15, dtype=tf.int32)\r\n",
        "        image = random_cutout(image, HEIGHT, WIDTH, \r\n",
        "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\r\n",
        "    elif p_cutout > .6: # 5~10 cut outs\r\n",
        "        n_cutout = tf.random.uniform([], 5, 10, dtype=tf.int32)\r\n",
        "        image = random_cutout(image, HEIGHT, WIDTH, \r\n",
        "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\r\n",
        "    elif p_cutout > .25: # 2~5 cut outs\r\n",
        "        n_cutout = tf.random.uniform([], 2, 5, dtype=tf.int32)\r\n",
        "        image = random_cutout(image, HEIGHT, WIDTH, \r\n",
        "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\r\n",
        "    else: # 1 cut out\r\n",
        "        image = random_cutout(image, HEIGHT, WIDTH, \r\n",
        "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=1)\r\n",
        "\r\n",
        "    return image\r\n",
        "\r\n",
        "def random_cutout(image, height, width, channels=3, min_mask_size=(10, 10), max_mask_size=(80, 80), k=1):\r\n",
        "    assert height > min_mask_size[0]\r\n",
        "    assert width > min_mask_size[1]\r\n",
        "    assert height > max_mask_size[0]\r\n",
        "    assert width > max_mask_size[1]\r\n",
        "\r\n",
        "    for i in range(k):\r\n",
        "      mask_height = tf.random.uniform(shape=[], minval=min_mask_size[0], maxval=max_mask_size[0], dtype=tf.int32)\r\n",
        "      mask_width = tf.random.uniform(shape=[], minval=min_mask_size[1], maxval=max_mask_size[1], dtype=tf.int32)\r\n",
        "\r\n",
        "      pad_h = height - mask_height\r\n",
        "      pad_top = tf.random.uniform(shape=[], minval=0, maxval=pad_h, dtype=tf.int32)\r\n",
        "      pad_bottom = pad_h - pad_top\r\n",
        "\r\n",
        "      pad_w = width - mask_width\r\n",
        "      pad_left = tf.random.uniform(shape=[], minval=0, maxval=pad_w, dtype=tf.int32)\r\n",
        "      pad_right = pad_w - pad_left\r\n",
        "\r\n",
        "      cutout_area = tf.zeros(shape=[mask_height, mask_width, channels], dtype=tf.uint8)\r\n",
        "\r\n",
        "      cutout_mask = tf.pad([cutout_area], [[0,0],[pad_top, pad_bottom], [pad_left, pad_right], [0,0]], constant_values=1)\r\n",
        "      cutout_mask = tf.squeeze(cutout_mask, axis=0)\r\n",
        "      image = tf.multiply(tf.cast(image, tf.float32), tf.cast(cutout_mask, tf.float32))\r\n",
        "\r\n",
        "    return image    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTNMtbp9Xkrz"
      },
      "source": [
        "# Auxilliary Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaKPmEZ4Xj4W"
      },
      "source": [
        "# data augmentation @cdeotte kernel: https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96\r\n",
        "def transform_rotation(image, height, rotation):\r\n",
        "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\r\n",
        "    # output - image randomly rotated\r\n",
        "    DIM = height\r\n",
        "    XDIM = DIM%2 #fix for size 331\r\n",
        "    \r\n",
        "    rotation = rotation * tf.random.uniform([1],dtype='float32')\r\n",
        "    # CONVERT DEGREES TO RADIANS\r\n",
        "    rotation = math.pi * rotation / 180.\r\n",
        "    \r\n",
        "    # ROTATION MATRIX\r\n",
        "    c1 = tf.math.cos(rotation)\r\n",
        "    s1 = tf.math.sin(rotation)\r\n",
        "    one = tf.constant([1],dtype='float32')\r\n",
        "    zero = tf.constant([0],dtype='float32')\r\n",
        "    rotation_matrix = tf.reshape(tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3])\r\n",
        "\r\n",
        "    # LIST DESTINATION PIXEL INDICES\r\n",
        "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\r\n",
        "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\r\n",
        "    z = tf.ones([DIM*DIM],dtype='int32')\r\n",
        "    idx = tf.stack( [x,y,z] )\r\n",
        "    \r\n",
        "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\r\n",
        "    idx2 = K.dot(rotation_matrix,tf.cast(idx,dtype='float32'))\r\n",
        "    idx2 = K.cast(idx2,dtype='int32')\r\n",
        "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\r\n",
        "    \r\n",
        "    # FIND ORIGIN PIXEL VALUES \r\n",
        "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\r\n",
        "    d = tf.gather_nd(image, tf.transpose(idx3))\r\n",
        "        \r\n",
        "    return tf.reshape(d,[DIM,DIM,3])\r\n",
        "\r\n",
        "def transform_shear(image, height, shear):\r\n",
        "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\r\n",
        "    # output - image randomly sheared\r\n",
        "    DIM = height\r\n",
        "    XDIM = DIM%2 #fix for size 331\r\n",
        "    \r\n",
        "    shear = shear * tf.random.uniform([1],dtype='float32')\r\n",
        "    shear = math.pi * shear / 180.\r\n",
        "        \r\n",
        "    # SHEAR MATRIX\r\n",
        "    one = tf.constant([1],dtype='float32')\r\n",
        "    zero = tf.constant([0],dtype='float32')\r\n",
        "    c2 = tf.math.cos(shear)\r\n",
        "    s2 = tf.math.sin(shear)\r\n",
        "    shear_matrix = tf.reshape(tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3])    \r\n",
        "\r\n",
        "    # LIST DESTINATION PIXEL INDICES\r\n",
        "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\r\n",
        "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\r\n",
        "    z = tf.ones([DIM*DIM],dtype='int32')\r\n",
        "    idx = tf.stack( [x,y,z] )\r\n",
        "    \r\n",
        "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\r\n",
        "    idx2 = K.dot(shear_matrix,tf.cast(idx,dtype='float32'))\r\n",
        "    idx2 = K.cast(idx2,dtype='int32')\r\n",
        "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\r\n",
        "    \r\n",
        "    # FIND ORIGIN PIXEL VALUES \r\n",
        "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\r\n",
        "    d = tf.gather_nd(image, tf.transpose(idx3))\r\n",
        "        \r\n",
        "    return tf.reshape(d,[DIM,DIM,3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoEXbkZuWOsQ"
      },
      "source": [
        "# Data Handling Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnYheGDAJr0W"
      },
      "source": [
        "def decode_image1(image_data):\r\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)  # image format uint8 [0,255]\r\n",
        "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\r\n",
        "    return image\r\n",
        "\r\n",
        "# Datasets utility functions\r\n",
        "def decode_image(image_data):\r\n",
        "    \"\"\"\r\n",
        "        Decode a JPEG-encoded image to a uint8 tensor.\r\n",
        "    \"\"\"\r\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\r\n",
        "    return image\r\n",
        "\r\n",
        "def scale_image(image, label):\r\n",
        "    \"\"\"\r\n",
        "        Cast tensor to float and normalizes (range between 0 and 1).\r\n",
        "    \"\"\"\r\n",
        "    image = tf.cast(image, tf.float32)\r\n",
        "    image /= 255.0\r\n",
        "    return image, label\r\n",
        "\r\n",
        "def prepare_image(image, label):\r\n",
        "    \"\"\"\r\n",
        "        Resize and reshape images to the expected size.\r\n",
        "    \"\"\"\r\n",
        "    image = tf.image.resize(image, [HEIGHT, WIDTH])\r\n",
        "    image = tf.reshape(image, [HEIGHT, WIDTH, 3])\r\n",
        "    return image, label\r\n",
        "\r\n",
        "def read_tfrecord(example, labeled):\r\n",
        "    tfrecord_format = {\r\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),\r\n",
        "        \"target\": tf.io.FixedLenFeature([], tf.int64)\r\n",
        "    } if labeled else {\r\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),\r\n",
        "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\r\n",
        "    }\r\n",
        "    \r\n",
        "    example = tf.io.parse_single_example(example, tfrecord_format)\r\n",
        "    image = decode_image(example['image'])\r\n",
        "    if labeled:\r\n",
        "        label = tf.cast(example['target'], tf.int32)\r\n",
        "        return image, label\r\n",
        "    idnum = example['image_name']\r\n",
        "    return image, idnum\r\n",
        "\"\"\"   \r\n",
        "    example = tf.io.parse_single_example(example, tfrecord_format)\r\n",
        "    image = decode_image(example['image'])\r\n",
        "    if labeled:\r\n",
        "        label_or_name = tf.cast(example['target'], tf.int32)\r\n",
        "        # One-Hot Encoding needed to use \"categorical_crossentropy\" loss\r\n",
        "        label_or_name = tf.one_hot(tf.cast(label_or_name, tf.int32), N_CLASSES)\r\n",
        "    else:\r\n",
        "        label_or_name = example['image_name']\r\n",
        "    return image, label_or_name\r\n",
        "\"\"\"\r\n",
        "##\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "def read_labeled_tfrecord(example):\r\n",
        "    LABELED_TFREC_FORMAT = {\r\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\r\n",
        "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\r\n",
        "    }\r\n",
        "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\r\n",
        "    image = decode_image(example['image'])\r\n",
        "    label = tf.cast(example['class'], tf.int32)\r\n",
        "    return image, label # returns a dataset of (image, label) pairs\r\n",
        "\r\n",
        "def read_unlabeled_tfrecord(example):\r\n",
        "    UNLABELED_TFREC_FORMAT = {\r\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\r\n",
        "        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\r\n",
        "        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\r\n",
        "    }\r\n",
        "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\r\n",
        "    image = decode_image(example['image'])\r\n",
        "    idnum = example['id']\r\n",
        "    return image, idnum # returns a dataset of image(s)\r\n",
        "\r\n",
        "def load_dataset(filenames, labeled=True, ordered=False):\r\n",
        "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\r\n",
        "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\r\n",
        "\r\n",
        "    ignore_order = tf.data.Options()\r\n",
        "    if not ordered:\r\n",
        "        ignore_order.experimental_deterministic = False # disable order, increase speed\r\n",
        "\r\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\r\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\r\n",
        "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\r\n",
        "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\r\n",
        "    return dataset\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def load_dataset(filenames, labeled=True, ordered=False):\r\n",
        "    ignore_order = tf.data.Options()\r\n",
        "    if not ordered:\r\n",
        "        ignore_order.experimental_deterministic = False # disable order, increase speed\r\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\r\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\r\n",
        "    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\r\n",
        "    return dataset\r\n",
        "\r\n",
        "def get_dataset(FILENAMES, labeled=True, ordered=False, repeated=False, \r\n",
        "                cached=False, augment=False):\r\n",
        "    \"\"\"\r\n",
        "        Return a Tensorflow dataset ready for training or inference.\r\n",
        "    \"\"\"\r\n",
        "    ignore_order = tf.data.Options()\r\n",
        "    if not ordered:\r\n",
        "        ignore_order.experimental_deterministic = False\r\n",
        "        dataset = tf.data.Dataset.list_files(FILENAMES)\r\n",
        "        dataset = dataset.interleave(tf.data.TFRecordDataset, num_parallel_calls=AUTO)\r\n",
        "    else:\r\n",
        "        dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads=AUTO)\r\n",
        "        \r\n",
        "    dataset = dataset.with_options(ignore_order)\r\n",
        "    \r\n",
        "    dataset = dataset.map(lambda x: read_tfrecord(x, labeled=labeled), num_parallel_calls=AUTO)\r\n",
        "    \r\n",
        "    if augment:\r\n",
        "        dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\r\n",
        "        \r\n",
        "    dataset = dataset.map(scale_image, num_parallel_calls=AUTO)\r\n",
        "    dataset = dataset.map(prepare_image, num_parallel_calls=AUTO)\r\n",
        "    \r\n",
        "    if not ordered:\r\n",
        "        dataset = dataset.shuffle(2048)\r\n",
        "    if repeated:\r\n",
        "        dataset = dataset.repeat()\r\n",
        "        \r\n",
        "    dataset = dataset.batch(BATCH_SIZE)\r\n",
        "    \r\n",
        "    if cached:\r\n",
        "        dataset = dataset.cache()\r\n",
        "    dataset = dataset.prefetch(AUTO)\r\n",
        "    return dataset\r\n",
        "\r\n",
        "def data_augment1(image, label):\r\n",
        "    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\r\n",
        "    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\r\n",
        "    # of the TPU while the TPU itself is computing gradients.\r\n",
        "    image = tf.image.random_flip_left_right(image)\r\n",
        "    image = tf.image.random_saturation(image, 0, 2)\r\n",
        "    return image, label   \r\n",
        "\r\n",
        "def get_training_dataset():\r\n",
        "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\r\n",
        "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\r\n",
        "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\r\n",
        "    dataset = dataset.shuffle(2048)\r\n",
        "    dataset = dataset.batch(BATCH_SIZE)\r\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\r\n",
        "    return dataset\r\n",
        "\r\n",
        "def get_validation_dataset(ordered=False):\r\n",
        "    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\r\n",
        "    dataset = dataset.batch(BATCH_SIZE)\r\n",
        "    dataset = dataset.cache()\r\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\r\n",
        "    return dataset\r\n",
        "\r\n",
        "def get_test_dataset(ordered=False):\r\n",
        "    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\r\n",
        "    dataset = dataset.batch(BATCH_SIZE)\r\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\r\n",
        "    return dataset\r\n",
        "\r\n",
        "def count_data_items(filenames):\r\n",
        "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\r\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\r\n",
        "    return np.sum(n)\r\n",
        "\r\n",
        "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\r\n",
        "NUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\r\n",
        "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\r\n",
        "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\r\n",
        "VALIDATION_STEPS = -(-NUM_VALIDATION_IMAGES // BATCH_SIZE) # The \"-(-//)\" trick rounds up instead of down :-)\r\n",
        "TEST_STEPS = (NUM_TEST_IMAGES // BATCH_SIZE)             # The \"-(-//)\" trick rounds up instead of down :-)\r\n",
        "print('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))\r\n",
        "print(STEPS_PER_EPOCH, VALIDATION_STEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XsKgLguXbI0"
      },
      "source": [
        "# Dataset visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BjiKQr2Jr3U"
      },
      "source": [
        "# data dump\r\n",
        "print(\"Training data shapes:\")\r\n",
        "for image, label in get_training_dataset().take(3):\r\n",
        "    print(image.numpy().shape, label.numpy().shape)\r\n",
        "print(\"Training data label examples:\", label.numpy())\r\n",
        "print(\"Validation data shapes:\")\r\n",
        "for image, label in get_validation_dataset().take(3):\r\n",
        "    print(image.numpy().shape, label.numpy().shape)\r\n",
        "print(\"Validation data label examples:\", label.numpy())\r\n",
        "print(\"Test data shapes:\")\r\n",
        "for image, idnum in get_test_dataset().take(3):\r\n",
        "    print(image.numpy().shape, idnum.numpy().shape)\r\n",
        "print(\"Test data IDs:\", idnum.numpy().astype('U')) # U=unicode string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHfMTvMLXi7O"
      },
      "source": [
        "# Peek at training data\r\n",
        "training_dataset = get_training_dataset()\r\n",
        "training_dataset = training_dataset.unbatch().batch(20)\r\n",
        "train_batch = iter(training_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uti0TOxPXi-o"
      },
      "source": [
        "# run this cell again for next set of images\r\n",
        "##display_batch_of_images(next(train_batch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOluKzxZJUpe"
      },
      "source": [
        "train_dataset = get_dataset(TRAINING_FILENAMES, ordered=True, augment=True)\r\n",
        "train_iter = iter(train_dataset.unbatch().batch(20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b4Tb2ZLLoxG"
      },
      "source": [
        "display_batch_of_images(next(train_iter))\r\n",
        "display_batch_of_images(next(train_iter))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJhKdl6gXjCk"
      },
      "source": [
        "# peer at test data\r\n",
        "test_dataset = get_test_dataset()\r\n",
        "test_dataset = test_dataset.unbatch().batch(1)\r\n",
        "test_batch = iter(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMucEn-XX0I2"
      },
      "source": [
        "# run this cell again for next set of images\r\n",
        "display_batch_of_images(next(test_batch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGnCWEGmMeyr"
      },
      "source": [
        "test_dataset = get_dataset(VALIDATION_FILENAMES, ordered=True, augment=False)\r\n",
        "test_iter = iter(test_dataset.unbatch().batch(20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r19oMfIlMJMA"
      },
      "source": [
        "#display_one_flower(test_dataset,'Test',1)\r\n",
        "##display_batch_of_images(next(test_iter))\r\n",
        "#test1 = test_dataset.unbatch()\r\n",
        "#display_batch_of_images(test1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHkEnxcwDCbA"
      },
      "source": [
        "# Label Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hKt6DfEDHLZ"
      },
      "source": [
        "#!gsutil ls -r gs://kds-7edb6b200570e03505c2c8b51546e17bfef2e493ee048343ac8fd722/*.csv\r\n",
        "#train = pd.read_csv('gs://kds-7edb6b200570e03505c2c8b51546e17bfef2e493ee048343ac8fd722/train.csv')\r\n",
        "train = pd.read_csv(f'{GCS_PATH}/train.csv')\r\n",
        "print(f'Train samples: {len(train)}')\r\n",
        "label_count = train.groupby('label', as_index=False).count()\r\n",
        "label_count.rename(columns={'image_id': 'Count', 'label': 'Label'}, inplace=True)\r\n",
        "label_count['Label'] = label_count['Label'].apply(lambda x: CLASSES[x])\r\n",
        "\r\n",
        "fig, ax = plt.subplots(1, 1, figsize=(18, 10))\r\n",
        "ax = sns.barplot(x=label_count['Count'], y=label_count['Label'], palette='viridis')\r\n",
        "ax.tick_params(labelsize=16)\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eacjr-oMBsnZ"
      },
      "source": [
        "# Balancing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqBjYR8eBytu"
      },
      "source": [
        "#Using class_weights did not seem to improve the results. To try Oversampling instead\r\n",
        "#initial_bias = np.log([COUNT_PNEUMONIA / COUNT_NORMAL])\r\n",
        "#print(\"Initial bias: {:.5f}\".format(initial_bias[0]))\r\n",
        "total_images = label_count['Count'].sum()\r\n",
        "print(total_images)\r\n",
        "\r\n",
        "#TRAIN_IMG_COUNT = COUNT_NORMAL + COUNT_PNEUMONIA\r\n",
        "label_count['weights'] = (1 / label_count['Count']) * (total_images) / 5.0\r\n",
        "#weight_for_1 = (1 / COUNT_PNEUMONIA) * (TRAIN_IMG_COUNT) / 2.0\r\n",
        "print(label_count)\r\n",
        "class_weight = dict(zip(label_count.index, label_count.weights))\r\n",
        "print(f'The weights are {class_weight}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUobr6CwX6d4"
      },
      "source": [
        "# Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAxbD3MxxVxK"
      },
      "source": [
        "initial_learning_rate = LEARNING_RATE #0.015\r\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\r\n",
        "    initial_learning_rate, decay_steps=100000, decay_rate=0.01, staircase=True #0.96\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Nyl2YZsrf4-"
      },
      "source": [
        "#es = tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy', mode='max',\r\n",
        "                       #patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\r\n",
        "\r\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto',\r\n",
        "                       patience=ES_PATIENCE, restore_best_weights=True, verbose=2)\r\n",
        "\r\n",
        "\r\n",
        "# Save the model with the minimum validation loss\r\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\r\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "        \"Cassava_best_model.h5\",\r\n",
        "        save_best_only=True,\r\n",
        "        monitor='sparse_categorical_accuracy',\r\n",
        "        mode='auto')\r\n",
        "\r\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\r\n",
        "        monitor='val_loss',\r\n",
        "        factor=0.3,\r\n",
        "        patience=2,\r\n",
        "        min_lr=1e-7,\r\n",
        "        mode='min',\r\n",
        "        verbose=1,\r\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ34yU9XSiar"
      },
      "source": [
        "decay_steps = 10000\r\n",
        "lr_decayed_fn = tf.keras.experimental.CosineDecay (\r\n",
        "    initial_learning_rate, decay_steps, alpha=0.1)\r\n",
        "\r\n",
        "callback_CosineDecay = tf.keras.callbacks.LearningRateScheduler(lr_decayed_fn, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACHiLDv-nznc"
      },
      "source": [
        "#EPOCHS = 12\r\n",
        "\r\n",
        "start_lr = LEARNING_RATE #0.00001\r\n",
        "min_lr = 1e-8 #0.00001\r\n",
        "#max_lr = 4e-5 * REPLICAS\r\n",
        "max_lr = 0.00000125 * REPLICAS * (NUM_TRAINING_IMAGES/250)\r\n",
        "rampup_epochs = 5\r\n",
        "sustain_epochs = 0\r\n",
        "exp_decay = 0.8\r\n",
        "\r\n",
        "def lrfn(epoch):\r\n",
        "  if epoch < rampup_epochs:\r\n",
        "    return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\r\n",
        "  elif epoch < rampup_epochs + sustain_epochs:\r\n",
        "    return max_lr\r\n",
        "  else:\r\n",
        "    return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\r\n",
        "    \r\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=True)\r\n",
        "\r\n",
        "rang = np.arange(EPOCHS)\r\n",
        "y = [lrfn(x) for x in rang]\r\n",
        "plt.plot(rang, y)\r\n",
        "print('Learning rate per epoch:')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIVDHURzo5pb"
      },
      "source": [
        "#COSINE ANNEALING --did not give very good results, probably due to low epochs(50)? Need checking. \r\n",
        "from math import floor, pi, cos\r\n",
        "# snapshot ensemble with custom learning rate schedule\r\n",
        "class CosineAnnealingLearningRateSchedule(Callback):\r\n",
        "\t# constructor\r\n",
        "\tdef __init__(self, n_epochs, n_cycles, lrate_max, verbose=0):\r\n",
        "\t\tself.epochs = n_epochs\r\n",
        "\t\tself.cycles = n_cycles\r\n",
        "\t\tself.lr_max = lrate_max\r\n",
        "\t\tself.lrates = list()\r\n",
        "\r\n",
        "\t# calculate learning rate for epoch\r\n",
        "\tdef cosine_annealing(self, epoch, n_epochs, n_cycles, lrate_max):\r\n",
        "\t\tepochs_per_cycle = floor(n_epochs/n_cycles)\r\n",
        "\t\tcos_inner = (pi * (epoch % epochs_per_cycle)) / (epochs_per_cycle)\r\n",
        "\t\treturn lrate_max/2 * (cos(cos_inner) + 1)\r\n",
        "\r\n",
        "\t# calculate and set learning rate at the start of the epoch\r\n",
        "\tdef on_epoch_begin(self, epoch, logs={}):\r\n",
        "\t\t# calculate learning rate\r\n",
        "\t\tlr = self.cosine_annealing(epoch, self.epochs, self.cycles, self.lr_max)\r\n",
        "\t\t# set learning rate\r\n",
        "\t\ttf.keras.backend.set_value(self.model.optimizer.lr, lr)\r\n",
        "\t\t# log value\r\n",
        "\t\tself.lrates.append(lr)\r\n",
        "\r\n",
        "\t# save models at the end of each cycle\r\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\r\n",
        "\t\t# check if we can save model\r\n",
        "\t\tepochs_per_cycle = floor(self.epochs / self.cycles)\r\n",
        "\t\tif epoch != 0 and (epoch + 1) % epochs_per_cycle == 0:\r\n",
        "\t\t\t# save model to file\r\n",
        "\t\t\tfilename = \"snapshot_model_%d.h5\" % int((epoch + 1) / epochs_per_cycle)\r\n",
        "\t\t\tself.model.save(filename)\r\n",
        "\t\t\tprint('>saved snapshot %s, epoch %d' % (filename, epoch))\r\n",
        "   \r\n",
        "n_cycles = EPOCHS/5\r\n",
        "cosine_anneal = CosineAnnealingLearningRateSchedule(EPOCHS, n_cycles, LEARNING_RATE,verbose=2) #0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ay8ZbHDtQfe"
      },
      "source": [
        "#Probably better running rate scheduler?\r\n",
        "LR_START = 1e-8\r\n",
        "LR_MIN = 1e-8\r\n",
        "LR_MAX = LEARNING_RATE\r\n",
        "LR_RAMPUP_EPOCHS = 3\r\n",
        "LR_SUSTAIN_EPOCHS = 0\r\n",
        "N_CYCLES = .5\r\n",
        "\r\n",
        "\r\n",
        "def lrfn1(epoch):\r\n",
        "    if epoch < LR_RAMPUP_EPOCHS:\r\n",
        "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\r\n",
        "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\r\n",
        "        lr = LR_MAX\r\n",
        "    else:\r\n",
        "        progress = (epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) / (EPOCHS - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)\r\n",
        "        lr = LR_MAX * (0.5 * (1.0 + tf.math.cos(math.pi * N_CYCLES * 2.0 * progress)))\r\n",
        "        if LR_MIN is not None:\r\n",
        "            lr = tf.math.maximum(LR_MIN, lr)\r\n",
        "            \r\n",
        "    return lr\r\n",
        "\r\n",
        "lr_callback1 = tf.keras.callbacks.LearningRateScheduler(lrfn1, verbose=2)\r\n",
        "\r\n",
        "rng = [i for i in range(EPOCHS)]\r\n",
        "y = [lrfn(x) for x in rng]\r\n",
        "\r\n",
        "sns.set(style='whitegrid')\r\n",
        "fig, ax = plt.subplots(figsize=(20, 6))\r\n",
        "plt.plot(rng, y)\r\n",
        "\r\n",
        "print(f'{EPOCHS} total epochs and {NUM_TRAINING_IMAGES//BATCH_SIZE} steps per epoch')\r\n",
        "print(f'Learning rate schedule: {y[0]:.3g} to {max(y):.3g} to {y[-1]:.3g}')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLbLN1ziBlv0"
      },
      "source": [
        "# The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85aDKAJXuxOT"
      },
      "source": [
        "def unfreeze_model(model):\r\n",
        "    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\r\n",
        "    for layer in model.layers[-20:]:\r\n",
        "        if not isinstance(layer, tf.keras.layers.BatchNormalization):\r\n",
        "            layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvK3p8qHX0MJ"
      },
      "source": [
        "tf.keras.backend.clear_session()\r\n",
        "\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "    #img_adjust_layer = tf.keras.layers.Lambda(lambda data: tf.keras.applications.xception.preprocess_input(tf.cast(data, tf.float32)), input_shape=[*IMAGE_SIZE, 3])\r\n",
        "    #pretrained_model = tf.keras.applications.Xception(weights='imagenet', include_top=False)\r\n",
        "    \r\n",
        "    #img_adjust_layer = tf.keras.layers.Lambda(lambda data: tf.keras.applications.vgg16.preprocess_input(tf.cast(data, tf.float32)), input_shape=[*IMAGE_SIZE, 3])\r\n",
        "    #pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False)\r\n",
        "    \r\n",
        "    img_adjust_layer = tf.keras.layers.Lambda(lambda data: tf.keras.applications.efficientnet.preprocess_input(tf.cast(data, tf.float32)), input_shape=[*IMAGE_SIZE, 3])\r\n",
        "    #input_image = tf.keras.layers.Input(shape=[*IMAGE_SIZE, 3], name='input_image')\r\n",
        "    pretrained_model = tf.keras.applications.EfficientNetB7(include_top=False, \r\n",
        "                                                      #weights='imagenet',\r\n",
        "                                                      drop_connect_rate=0.6,\r\n",
        "                                                      #input_tensor=input_image\r\n",
        "                                                      #pooling='avg')\r\n",
        "                                                           )\r\n",
        "    ##pretrained_model.trainable = True # False = transfer learning, True = fine-tuning\r\n",
        "    pretrained_model.load_weights('/content/efficientnet-b7_noisy-student_notop.h5',by_name=True)\r\n",
        "    unfreeze_model(pretrained_model)\r\n",
        "    \r\n",
        "    model = tf.keras.Sequential([\r\n",
        "        img_adjust_layer,\r\n",
        "        #tf.keras.layers.BatchNormalization(renorm=True),\r\n",
        "        pretrained_model,\r\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\r\n",
        "        tf.keras.layers.Flatten(),\r\n",
        "        tf.keras.layers.Dense(256,activation='relu'),#,bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.001)\r\n",
        "        ##tf.keras.layers.BatchNormalization(), #momentum=0.95\r\n",
        "        tf.keras.layers.Dropout(0.5),\r\n",
        "        tf.keras.layers.Dense(128,activation='relu'),\r\n",
        "        tf.keras.layers.Dense(N_CLASSES, activation='softmax',name='output')\r\n",
        "    ])\r\n",
        "     #optimizer= tf.keras.optimizers.Adam(learning_rate=lr_schedule)\r\n",
        "     \r\n",
        "    \r\n",
        "\r\n",
        "    model.compile(\r\n",
        "        optimizer= tf.keras.optimizers.Adam(LEARNING_RATE),\r\n",
        "        loss = 'sparse_categorical_crossentropy', #tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.01), \r\n",
        "        metrics= ['sparse_categorical_accuracy'],\r\n",
        "        # NEW on TPU in TensorFlow 24: sending multiple batches to the TPU at once saves communications\r\n",
        "        # overheads and allows the XLA compiler to unroll the loop on TPU and optimize hardware utilization.\r\n",
        "        steps_per_execution=125 #208\r\n",
        "    )\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lvY2LjVYHC6"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2Dol4MGYLBP"
      },
      "source": [
        "#history = model.fit(get_training_dataset(), steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS,\r\n",
        "         #           validation_data=get_validation_dataset(), validation_steps=VALIDATION_STEPS,\r\n",
        "         #           callbacks=[es, checkpoint_cb, reduce_lr])\r\n",
        "\r\n",
        "history = model.fit(get_dataset(TRAINING_FILENAMES, ordered=False, augment=True).repeat(), \r\n",
        "                    steps_per_epoch=STEPS_PER_EPOCH, \r\n",
        "                    epochs=EPOCHS,\r\n",
        "                    validation_data=get_dataset(VALIDATION_FILENAMES, ordered=False, augment=False).repeat(), validation_steps=VALIDATION_STEPS,\r\n",
        "                    class_weight=class_weight,\r\n",
        "                    callbacks=[es, checkpoint_cb, lr_callback]) # cosine_anneal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGPdfzH-YLN7"
      },
      "source": [
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 211)\r\n",
        "display_training_curves(history.history['sparse_categorical_accuracy'], history.history['val_sparse_categorical_accuracy'], 'accuracy', 212)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmuxYjxuYeiZ"
      },
      "source": [
        "Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVU-Eo9gYfVP"
      },
      "source": [
        "#cmdataset = get_validation_dataset(ordered=True) # since we are splitting the dataset and iterating separately on images and labels, order matters.\r\n",
        "cmdataset = get_dataset(VALIDATION_FILENAMES, ordered=True,augment=False) # since we are splitting the dataset and iterating separately on images and labels, order matters.\r\n",
        "images_ds = cmdataset.map(lambda image, label: image)\r\n",
        "labels_ds = cmdataset.map(lambda image, label: label).unbatch()\r\n",
        "cm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy() # get everything as one batch NUM_VALIDATION_IMAGES 8000\r\n",
        "cm_probabilities = model.predict(images_ds, steps=VALIDATION_STEPS)\r\n",
        "cm_predictions = np.argmax(cm_probabilities, axis=-1)\r\n",
        "print(\"Correct   labels: \", cm_correct_labels.shape, cm_correct_labels)\r\n",
        "print(\"Predicted labels: \", cm_predictions.shape, cm_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sr7oA70Yf0t"
      },
      "source": [
        "cmat = confusion_matrix(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)))\r\n",
        "score = f1_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\r\n",
        "precision = precision_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\r\n",
        "recall = recall_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\r\n",
        "cmat = (cmat.T / cmat.sum(axis=1)).T # normalized\r\n",
        "display_confusion_matrix(cmat, score, precision, recall)\r\n",
        "print('f1 score: {:.3f}, precision: {:.3f}, recall: {:.3f}'.format(score, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1PINPzzM1BK"
      },
      "source": [
        "#from sklearn.metrics import plot_confusion_matrix\r\n",
        "#plot_confusion_matrix(X=cm_predictions,y_true=cm_correct_labels)\r\n",
        "ax = plt.subplot()\r\n",
        "ax.matshow(cmat,cmap='Reds')\r\n",
        "#labels= [print(i) for i in CLASSES]\r\n",
        "ax.set_xticklabels(['']+CLASSES)\r\n",
        "ax.set_yticklabels(['']+CLASSES)\r\n",
        "ax.set_xlabel('Predicted Label')\r\n",
        "ax.set_ylabel('True Labels')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdAJzLvKWvme"
      },
      "source": [
        "ax1 = plt.subplot()\r\n",
        "sns.heatmap(cmat, annot=True,ax=ax1)\r\n",
        "#ax1.set_xticklabels(['']+CLASSES)\r\n",
        "#ax1.set_yticklabels(['']+CLASSES)\r\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4v5LznkXlQe"
      },
      "source": [
        "\"\"\"\r\n",
        "for image, idnum in get_test_dataset().take(3):\r\n",
        "    print(image.numpy().shape, idnum.numpy().shape)\r\n",
        "print(\"Test data IDs:\", idnum.numpy().astype('U')) # U=unicode string\r\n",
        "test_images_ds = test_ds.map(lambda image, idnum: image)\r\n",
        "print(test_images_ds)\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERBY9d2hYnmT"
      },
      "source": [
        "Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaHJXNX-Yv48"
      },
      "source": [
        "\"\"\"\r\n",
        "test_ds = get_dataset(TEST_FILENAMES,ordered=True) # since we are splitting the dataset and iterating separately on images and ids, order matters.\r\n",
        "#test_ds = get_test_dataset().unbatch().batch(1)\r\n",
        "#print(count_data_items(test_ds))\r\n",
        "print('Computing predictions...') #\r\n",
        "test_images_ds = test_ds.map(lambda image, idnum: image)\r\n",
        "probabilities = model.predict(test_images_ds,steps=1) #,TEST_STEPS\r\n",
        "predictions = np.argmax(probabilities, axis=-1)\r\n",
        "print(predictions)\r\n",
        "\r\n",
        "print('Generating submission.csv file...')\r\n",
        "test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\r\n",
        "test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch\r\n",
        "np.savetxt('submission.csv', np.rec.fromarrays([test_ids, predictions]), fmt=['%s', '%d'], delimiter=',', header='id,label', comments='')\r\n",
        "!head submission.csv\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY56DLroY0Il"
      },
      "source": [
        "Visual validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNHltJaqZkoc"
      },
      "source": [
        "#dataset = get_validation_dataset()\r\n",
        "dataset = get_dataset(VALIDATION_FILENAMES)\r\n",
        "dataset = dataset.unbatch().batch(20)\r\n",
        "batch = iter(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNJB6jnaZxjm"
      },
      "source": [
        "# run this cell again for next set of images\r\n",
        "images, labels = next(batch)\r\n",
        "probabilities = model.predict(tf.cast(images, tf.float32))\r\n",
        "predictions = np.argmax(probabilities, axis=-1)\r\n",
        "display_batch_of_images((images, labels), predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh9QNXyFIdM7"
      },
      "source": [
        "Test images\r\n",
        "\r\n",
        "Learning rate\r\n",
        "\r\n",
        "Augmentation style\r\n",
        "\r\n",
        "Model imported/ compare with others\r\n",
        "\r\n",
        "Weights to balance the data in the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHFbQsFOgLuy"
      },
      "source": [
        "!gsutil ls $GCS_PATH/test_images\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdOYeLRnzAsR"
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzsWn09oDqsb"
      },
      "source": [
        "# Using K_FOLD VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uu1Zmv-Ylii"
      },
      "source": [
        "#SKFOLD for comparison\r\n",
        "skf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\r\n",
        "oof_pred = []; oof_labels = []; history_list = []\r\n",
        "#TRAIN_FILENAMES= ''\r\n",
        "for fold,(idxT, idxV) in enumerate(skf.split(np.arange(15))):\r\n",
        "    ##if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\r\n",
        "    print(f'\\nFOLD: {fold+1}')\r\n",
        "    print(f'TRAIN: {idxT} VALID: {idxV}')\r\n",
        "\r\n",
        "    # Create train and validation sets\r\n",
        "    ALL_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train_tfrecords/ld_train*.tfrec')\r\n",
        "    #print(count_data_items(ALL_FILENAMES))\r\n",
        "   \r\n",
        "    #TRAIN_FILENAMES = tf.io.gfile.glob([GCS_PATH + '/Id_train%.2i*.tfrec' % x for x in idxT])\r\n",
        "    #print(TRAIN_FILENAMES)\r\n",
        "    TRAIN_FILENAMES = tf.io.gfile.glob([GCS_PATH + '/train_tfrecords/ld_train%.2i*.tfrec' % x for x in idxT])\r\n",
        "    ##print(count_data_items(TRAIN_FILENAMES))\r\n",
        "    STEPS1_PER_EPOCH = -(-count_data_items(TRAIN_FILENAMES) // BATCH_SIZE)\r\n",
        "    #VALID_FILENAMES = tf.io.gfile.glob([GCS_PATH + '/Id_train%.2i*.tfrec' % x for x in idxV])\r\n",
        "    VALID_FILENAMES = tf.io.gfile.glob([GCS_PATH + '/train_tfrecords/ld_train%.2i*.tfrec' % x for x in idxV])\r\n",
        "    #print(count_data_items(VALID_FILENAMES))\r\n",
        "\r\n",
        "    np.random.shuffle(TRAIN_FILENAMES)\r\n",
        "    ct_train = count_data_items(TRAIN_FILENAMES)\r\n",
        "    #print(ct_train)\r\n",
        "    VALID_STEPS = -(-count_data_items(VALID_FILENAMES) // BATCH_SIZE) #round updwards trick\r\n",
        "        \r\n",
        "    ## MODEL\r\n",
        "    K.clear_session()\r\n",
        "    #with strategy.scope():\r\n",
        "        #model = model_fn((None, None, CHANNELS), N_CLASSES)\r\n",
        "        \r\n",
        "    model_path = f'model_{fold}.h5'\r\n",
        "        #es = EarlyStopping(monitor='val_sparse_categorical_accuracy', mode='max', \r\n",
        "         #                 patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\r\n",
        "\r\n",
        "        ## TRAIN\r\n",
        "    history = model.fit(x=get_dataset(TRAIN_FILENAMES, labeled=True, ordered=False, repeated=True, augment=True).repeat(), \r\n",
        "                            validation_data=get_dataset(VALID_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False).repeat(), \r\n",
        "                            #steps_per_epoch=(ct_train // BATCH_SIZE), \r\n",
        "                            steps_per_epoch = STEPS1_PER_EPOCH,\r\n",
        "                            validation_steps = VALID_STEPS,\r\n",
        "                            callbacks=[es, lr_callback ], #LearningRateScheduler(lrfn, verbose=2)\r\n",
        "                            class_weight=class_weight,\r\n",
        "                            epochs=EPOCHS,  \r\n",
        "                            verbose=2).history\r\n",
        "          \r\n",
        "    history_list.append(history)\r\n",
        "        # Save last model weights\r\n",
        "    model.save_weights(model_path)\r\n",
        "\r\n",
        "    # OOF predictions\r\n",
        "    ds_valid = get_dataset(VALID_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False)\r\n",
        "    oof_labels.append([target.numpy() for img, target in iter(ds_valid.unbatch())])\r\n",
        "    x_oof = ds_valid.map(lambda image, image_name: image)\r\n",
        "    oof_pred.append(np.argmax(model.predict(x_oof, steps=VALID_STEPS), axis=-1))\r\n",
        "    \r\n",
        "    ## RESULTS\r\n",
        "    print(f\"#### FOLD {fold+1} OOF Accuracy = {np.max(history['val_sparse_categorical_accuracy']):.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGkTIQpP-jhn"
      },
      "source": [
        "# Fold Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-YpAnmUH5xn"
      },
      "source": [
        "for fold, history in enumerate(history_list):\r\n",
        "    print(f'\\nFOLD: {fold+1}')\r\n",
        "    plot_metrics(history)\r\n",
        "    #display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 211)\r\n",
        "    #display_training_curves(history.history['sparse_categorical_accuracy'], history.history['val_sparse_categorical_accuracy'], 'accuracy', 212)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njPZ5vdxQEI0"
      },
      "source": [
        "# Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvXpVGqg7Dlh"
      },
      "source": [
        "y_true = np.concatenate(oof_labels)\r\n",
        "y_preds = np.concatenate(oof_pred)\r\n",
        "\r\n",
        "print(classification_report(y_true, y_preds, target_names=CLASSES))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un30VO-e-V2M"
      },
      "source": [
        "# Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY2hG2k_7xtC"
      },
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(20, 12))\r\n",
        "train_cfn_matrix = confusion_matrix(y_true, y_preds, labels=range(len(CLASSES)))\r\n",
        "train_cfn_matrix = (train_cfn_matrix.T / train_cfn_matrix.sum(axis=1)).T\r\n",
        "train_df_cm = pd.DataFrame(train_cfn_matrix, index=CLASSES, columns=CLASSES)\r\n",
        "ax = sns.heatmap(train_df_cm, cmap='Blues', annot=True, fmt='.2f', linewidths=.5).set_title('Train', fontsize=30)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR0Kcrnb9dax"
      },
      "source": [
        "# Visual Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuG6VWFm9EeV"
      },
      "source": [
        "#Use same images as in train-test split for rough comparison\r\n",
        "#dataset = get_validation_dataset()\r\n",
        "dataset = get_dataset(VALIDATION_FILENAMES)\r\n",
        "dataset = dataset.unbatch().batch(20)\r\n",
        "batch = iter(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktPeu6Ag9Evb"
      },
      "source": [
        "# run this cell again for next set of images\r\n",
        "images, labels = next(batch)\r\n",
        "probabilities = model.predict(tf.cast(images, tf.float32))\r\n",
        "predictions = np.argmax(probabilities, axis=-1)\r\n",
        "display_batch_of_images((images, labels), predictions)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}